# -*- coding: utf-8 -*-
import streamlit as st
import urllib.request
import urllib.parse
import json
import pandas as pd
import sqlite3
import os
from openai import OpenAI

# Secrets ê°€ì ¸ì˜¤ê¸° (Streamlit Cloudì— ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ í•¨)
NAVER_CLIENT_ID = st.secrets["NAVER_CLIENT_ID"]
NAVER_CLIENT_SECRET = st.secrets["NAVER_CLIENT_SECRET"]
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
os.environ["LANGSMITH_PROJECT"] = "naver_shopping_ai"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê´‘ê³  ì—†ëŠ” ì° ë¦¬ë·° í™•ì¸í•˜ê¸°",
    page_icon="ğŸ“",
    layout="wide"
)

# DB ì´ˆê¸°í™” í•¨ìˆ˜
def init_db():
    db_dir = os.path.join(os.getcwd(), "data")
    os.makedirs(db_dir, exist_ok=True)
    db_path = os.path.join(db_dir, "reviews.db")
    conn = sqlite3.connect(db_path)
    c = conn.cursor()
    c.execute('''
    CREATE TABLE IF NOT EXISTS blog_posts (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        product_name TEXT NOT NULL,
        title TEXT NOT NULL,
        description TEXT,
        link TEXT,
        blogger_name TEXT,
        post_date TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
    ''')
    c.execute('''
    CREATE TABLE IF NOT EXISTS analysis_results (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        product_name TEXT NOT NULL,
        positive_opinions TEXT,
        negative_opinions TEXT,
        summary TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
    ''')
    conn.commit()
    return conn, c

# Naver API client í´ë˜ìŠ¤
class NaverApiClient:
    def __init__(self, client_id, client_secret):
        self.client_id = client_id
        self.client_secret = client_secret
        self.base_url = "https://openapi.naver.com/v1/search/"

    def get_data(self, media, count, query, start=1, sort="date"):
        encText = urllib.parse.quote(query)
        url = f"{self.base_url}{media}?sort={sort}&display={count}&start={start}&query={encText}"

        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", self.client_id)
        request.add_header("X-Naver-Client-Secret", self.client_secret)

        try:
            response = urllib.request.urlopen(request)
            rescode = response.getcode()

            if rescode == 200:
                response_body = response.read()
                return response_body.decode('utf-8')
            else:
                st.error(f"Naver API Error Code: {rescode}")
                return None
        except Exception as e:
            st.error(f"Naver API Exception: {e}")
            return None

    def get_blog(self, query, count=10, start=1, sort="date"):
        return self.get_data("blog", count, query, start, sort)

    def parse_json(self, data):
        if data:
            return json.loads(data)
        return None

# DBì— ë¸”ë¡œê·¸ ë°ì´í„° ì €ì¥ í•¨ìˆ˜
def save_blog_data_to_db(conn, cursor, blog_data, product_name):
    if not blog_data or "items" not in blog_data or not blog_data["items"]:
        st.warning("ì²˜ë¦¬í•  ë¸”ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    cursor.execute("DELETE FROM blog_posts WHERE product_name = ?", (product_name,))

    count = 0
    for item in blog_data["items"]:
        title = item["title"].replace("<b>", "").replace("</b>", "").replace("&quot;", '"')
        description = item["description"].replace("<b>", "").replace("</b>", "").replace("&quot;", '"')

        cursor.execute('''
        INSERT INTO blog_posts (product_name, title, description, link, blogger_name, post_date)
        VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            product_name,
            title,
            description,
            item.get("link", ""),
            item.get("bloggername", ""),
            item.get("postdate", "")
        ))
        count += 1

    conn.commit()
    st.success(f"{count}ê°œì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return count

# DBì—ì„œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
def get_blog_posts(cursor, product_name, limit=50):
    cursor.execute("""
    SELECT title, description, blogger_name, post_date, link
    FROM blog_posts
    WHERE product_name = ?
    LIMIT ?
    """, (product_name, limit))
    return cursor.fetchall()

# ë¶„ì„ ê²°ê³¼ DB ì €ì¥
def save_analysis_result(conn, cursor, product_name, positive, negative, summary):
    cursor.execute("DELETE FROM analysis_results WHERE product_name = ?", (product_name,))
    cursor.execute('''
    INSERT INTO analysis_results (product_name, positive_opinions, negative_opinions, summary)
    VALUES (?, ?, ?, ?)
    ''', (product_name, positive, negative, summary))
    conn.commit()

# ë¶„ì„ ê²°ê³¼ DBì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
def get_analysis_result(cursor, product_name):
    cursor.execute("""
    SELECT positive_opinions, negative_opinions, summary
    FROM analysis_results
    WHERE product_name = ?
    """, (product_name,))
    return cursor.fetchone()

# ChatGPT APIë¥¼ ì´ìš©í•œ ë¦¬ë·° ë¶„ì„ í•¨ìˆ˜
def analyze_reviews(api_key, reviews_text, product_name):
    if not api_key:
        st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return None, None, None

    try:
        import openai
        openai.api_key = api_key

        max_chars = 15000
        if len(reviews_text) > max_chars:
            st.warning(f"ë¦¬ë·° í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì²˜ìŒ {max_chars} ë¬¸ìë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")
            reviews_text = reviews_text[:max_chars] + "... (ì´í•˜ ìƒëµ)"

        prompt = f"""
ë‹¤ìŒì€ '{product_name}'ì— ëŒ€í•œ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í•´ë‹¹ ì½˜í…ì¸ ë¥¼ ì² ì €íˆ ë¶„ì„í•˜ì—¬ ì•„ë˜ ìš”ì²­ì‚¬í•­ì— ë”°ë¼ ì‘ë‹µí•´ì£¼ì„¸ìš”:

1. ê´‘ê³ ì„± ì½˜í…ì¸  ì‹ë³„:
- ë¨¼ì € ì œê³µëœ ê¸€ì´ ê´‘ê³ ì„± ì½˜í…ì¸ ì¸ì§€ ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•´ì£¼ì„¸ìš”.
- íŒë‹¨ ê¸°ì¤€: í˜‘ì°¬/ê´‘ê³  ë¬¸êµ¬ ëª…ì‹œ, ì§€ë‚˜ì¹˜ê²Œ ê¸ì •ì ì¸ ì–´ì¡°, êµ¬ë§¤ ë§í¬ ë‹¤ìˆ˜ í¬í•¨, ìƒí’ˆ í™ë³´ì— ì¹˜ì¤‘ëœ ë‚´ìš© ë“±
- ê´‘ê³ ì„± ì½˜í…ì¸ ë¡œ íŒë‹¨ë˜ë©´ í•´ë‹¹ ë‚´ìš©ì€ ì˜ê²¬ ë¶„ì„ì—ì„œ ì œì™¸í•˜ê±°ë‚˜ ë¹„ì¤‘ì„ ë‚®ì¶°ì£¼ì„¸ìš”.

2. ê¸ì •ì  ì˜ê²¬ ë¶„ì„:
- ì‹¤ì œ ì‚¬ìš©ìê°€ ì§ì ‘ ê²½í—˜í•œ êµ¬ì²´ì ì¸ ì¥ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
- ê°ê´€ì  ì‚¬ì‹¤ê³¼ ì£¼ê´€ì  ë§Œì¡±ë„ë¥¼ êµ¬ë¶„í•˜ì—¬ ì„œìˆ í•´ì£¼ì„¸ìš”.
- ê°€ì¥ ìì£¼ ì–¸ê¸‰ë˜ëŠ” ê¸ì •ì  íŠ¹ì§•ì„ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨í•´ì£¼ì„¸ìš”.
- 5-7ì¤„ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

3. ë¶€ì •ì  ì˜ê²¬ ë¶„ì„:
- ì‹¤ì œ ì‚¬ìš©ìì˜ ë¶ˆë§Œì‚¬í•­ê³¼ ê°œì„ ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
- ë‹¨ìˆœí•œ ë¶ˆí‰ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ë‹¨ì ê³¼ ë¬¸ì œì ì— ì´ˆì ì„ ë§ì¶°ì£¼ì„¸ìš”.
- ê°€ì¥ ìì£¼ ì–¸ê¸‰ë˜ëŠ” ë¶€ì •ì  íŠ¹ì§•ì„ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨í•´ì£¼ì„¸ìš”.
- 5-7ì¤„ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
- ë¶€ì •ì  ì˜ê²¬ì´ ê±°ì˜ ì—†ëŠ” ê²½ìš°, ê·¸ ì´ìœ (ê´‘ê³ ì„± ê¸€ì´ ë§ì€ì§€, ì œí’ˆì´ ì‹¤ì œë¡œ ë§Œì¡±ë„ê°€ ë†’ì€ì§€ ë“±)ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

4. ì¢…í•© í‰ê°€:
- ê¸ì •/ë¶€ì • ì˜ê²¬ì˜ ë¹„ìœ¨ê³¼ ì‹ ë¢°ë„ë¥¼ ê³ ë ¤í•œ ê· í˜• ì¡íŒ ì´í‰ì„ ì œê³µí•´ì£¼ì„¸ìš”.
- ê´‘ê³ ì„± ì½˜í…ì¸ ì˜ ë¹„ì¤‘ì„ ê³ ë ¤í•˜ì—¬ ì‹¤ì œ ì‚¬ìš©ì ì˜ê²¬ì´ ì–¼ë§ˆë‚˜ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
- ì œí’ˆì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì‚¬ìš©ì ë§Œì¡±ë„ë¥¼ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
- 5-7ì¤„ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ë¸”ë¡œê·¸ ë‚´ìš©:
{reviews_text}

ì‘ë‹µì€ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ë˜ Markdownì¶œë ¥ì€ ì‚¬ìš©í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”:
{{
\"ad_analysis\": \"ê´‘ê³ ì„± ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼ (ê´‘ê³ ì„± ì½˜í…ì¸  ë¹„ìœ¨ ì¶”ì •ì¹˜ í¬í•¨)\",
\"positive\": \"êµ¬ì²´ì ì¸ ê¸ì •ì  ì˜ê²¬ ìš”ì•½ (ì‹¤ì œ ì‚¬ìš©ì ê²½í—˜ ì¤‘ì‹¬)\",
\"negative\": \"êµ¬ì²´ì ì¸ ë¶€ì •ì  ì˜ê²¬ ìš”ì•½ (ì‹¤ì œ ì‚¬ìš©ì ê²½í—˜ ì¤‘ì‹¬)\",
\"summary\": \"ê°ê´€ì ì¸ ì „ì²´ ìš”ì•½ ë° ì¢…í•© í‰ê°€\"
}}
"""

        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì œí’ˆ ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì½˜í…ì¸ ë¥¼ ì² ì €íˆ ë¶„ì„í•˜ì—¬ ê´‘ê³ ì„± ê¸€ì„ ì‹ë³„í•˜ê³ , ì‹¤ì œ ì‚¬ìš©ì ê²½í—˜ì— ê¸°ë°˜í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ëŠ¥ë ¥ì´ ìˆìŠµë‹ˆë‹¤. ë¶„ì„ ì‹œ ê°ê´€ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ í•˜ê³ , ê¸ì •/ë¶€ì • ì˜ê²¬ì˜ íŒ¨í„´ì„ íŒŒì•…í•˜ì—¬ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•©ë‹ˆë‹¤. ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹Œ ì‹¬ì¸µì  ë¶„ì„ì„ ì œê³µí•˜ë©°, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¢…í•© í‰ê°€ë¥¼ ì œì‹œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=2048
        )

        content = response.choices[0].message.content.strip()

        if not content:
            st.error("ChatGPT ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return None, None, None

        try:
            result = json.loads(content)
            return result["positive"], result["negative"], result["summary"]
        except json.JSONDecodeError as e:
            st.error(f"JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.text_area("ì‘ë‹µ ì›ë¬¸ ë³´ê¸°", content, height=300)
            return None, None, None

    except Exception as e:
        st.error(f"ChatGPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, None, None

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í•¨ìˆ˜
def main():
    st.markdown("""
    <div style="background-color: #f9f9f9; padding: 20px; border-radius: 10px; text-align: center;">
        <span style="color: #03c75a; font-size: 40px; font-weight: bold;">Naver Blog </span>
        <span style="color: #000000; font-size: 35px; font-weight: bold;">  ì œí’ˆ ë¦¬ë·° ë¶„ì„ ì½”íŒŒì¼ëŸ¿</span>
    </div>
    """, unsafe_allow_html=True)

    # DB ì—°ê²° ë° í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    conn, cursor = init_db()
    naver_client = NaverApiClient(NAVER_CLIENT_ID, NAVER_CLIENT_SECRET)

    # ì œí’ˆ ê²€ìƒ‰ ë° ë¶„ì„ UI
    st.markdown("##")
    st.subheader("ì œí’ˆ ê²€ìƒ‰ ë° ë¶„ì„")

    product_name = st.text_input("ì œí’ˆëª… ì…ë ¥", "")

    col1, col2 = st.columns([2, 2])

    with col1:
        count = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=10, max_value=100, value=50)

    with col2:
        sort_options = st.selectbox(
            "ì •ë ¬",
            options=[("ìµœì‹ ìˆœ", "date"), ("ì •í™•ë„ìˆœ", "sim")],
            format_func=lambda x: x[0]
        )
        sort_option = sort_options[1]

    # ê²€ìƒ‰ ë° ë¶„ì„ ë²„íŠ¼ ë°°ì¹˜
    with col1:
        search_col, analyze_col = st.columns(2)
        with search_col:
            search_button = st.button("ê²€ìƒ‰", type="primary")
        with analyze_col:
            analyze_button = st.button("ë¶„ì„")

    # ê²€ìƒ‰ ì²˜ë¦¬
    if search_button and product_name:
        with st.spinner(f"'{product_name}'ì— ëŒ€í•œ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì¤‘..."):
            data = naver_client.get_blog(product_name, count, sort=sort_option)
            parsed_data = naver_client.parse_json(data)

            if parsed_data and "items" in parsed_data and parsed_data["items"]:
                save_blog_data_to_db(conn, cursor, parsed_data, product_name)

                st.subheader(f"ê²€ìƒ‰ ê²°ê³¼ (ì´ {parsed_data['total']}ê°œ ì¤‘ {len(parsed_data['items'])}ê°œ í‘œì‹œ)")

                df = pd.DataFrame(parsed_data["items"])

                for col in ['title', 'description']:
                    if col in df.columns:
                        df[col] = df[col].str.replace('<b>', '').str.replace('</b>', '').str.replace('&quot;', '"')

                display_cols = ['title', 'description', 'postdate', 'bloggername']
                display_cols = [col for col in display_cols if col in df.columns]

                st.dataframe(df[display_cols], use_container_width=True)

                st.session_state.search_results_available = True
                st.session_state.current_product = product_name
            else:
                st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.session_state.search_results_available = False

    # ë¶„ì„ ì²˜ë¦¬
    if (analyze_button or st.session_state.get("analyze_clicked", False)) and st.session_state.get("search_results_available", False):
        st.session_state.analyze_clicked = True

        st.markdown("---")
        st.subheader("ë¦¬ë·° ë¶„ì„")
        st.markdown(f"**'{st.session_state.current_product}'** ì— ëŒ€í•œ ë¸”ë¡œê·¸ ë¦¬ë·°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        st.markdown("---")

        existing_analysis = get_analysis_result(cursor, st.session_state.current_product)

        if existing_analysis and not st.session_state.get("reanalyze", False):
            positive, negative, summary = existing_analysis

            st.subheader("ê¸°ì¡´ ë¶„ì„ ê²°ê³¼")
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### ğŸ‘ ê¸ì •ì  ì˜ê²¬")
                st.markdown(positive)

            with col2:
                st.markdown("### ğŸ‘ ë¶€ì •ì  ì˜ê²¬")
                st.markdown(negative)

            st.markdown("### ğŸ“‹ ì „ì²´ ìš”ì•½ ë° ì´í‰")
            st.markdown(summary)

            if st.button("ì¬ë¶„ì„ ì‹¤í–‰"):
                st.session_state["reanalyze"] = True
                st.experimental_rerun()

        else:
            with st.spinner("ë¦¬ë·° ë°ì´í„° ë¶„ì„ ì¤‘..."):
                blog_posts = get_blog_posts(cursor, st.session_state.current_product)

                if blog_posts:
                    all_posts_text = "\n\n".join([
                        f"ì œëª©: {post[0]}\në‚´ìš©: {post[1]}\nì‘ì„±ì: {post[2]}\në‚ ì§œ: {post[3]}"
                        for post in blog_posts
                    ])

                    positive, negative, summary = analyze_reviews(OPENAI_API_KEY, all_posts_text, st.session_state.current_product)

                    if positive and negative and summary:
                        save_analysis_result(conn, cursor, st.session_state.current_product, positive, negative, summary)

                        st.subheader("ë¦¬ë·° ë¶„ì„ ê²°ê³¼")
                        col1, col2 = st.columns(2)

                        with col1:
                            st.markdown("### ğŸ‘ ê¸ì •ì  ì˜ê²¬")
                            st.markdown(positive)

                        with col2:
                            st.markdown("### ğŸ‘ ë¶€ì •ì  ì˜ê²¬")
                            st.markdown(negative)

                        st.markdown("### ğŸ“‹ ì „ì²´ ìš”ì•½ ë° ì´í‰")
                        st.markdown(summary)

                        st.session_state.reanalyze = False
                    else:
                        st.error("ë¦¬ë·° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning(f"'{st.session_state.current_product}'ì— ëŒ€í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê²€ìƒ‰ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

    # DB ì—°ê²° ì¢…ë£Œ
    conn.close()

    # ê´‘ê³  ë°°ë„ˆ í‘œì‹œ
    show_ad = st.session_state.get("show_ad", True)
    st.markdown("---")
    ad_container = st.container()
    if show_ad:
        with ad_container:
            st.markdown("""
            <div style="border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin-top: 10px;">
                <h3 style="margin-top: 0;">ğŸ” ì¶”ì²œ ì œí’ˆ</h3>
                <div style="display: flex; align-items: center;">
                    <a href="https://www.coupang.com/vp/products/6795965704?itemId=12628460347&vendorItemId=79896126181&q=%ED%95%98%EB%A6%BC+%EB%8B%AD%EA%B0%80%EC%8A%B4%EC%82%B4&itemsCount=36&searchId=7e7113a8513528&rank=3&searchRank=3&isAddedCart=" target="_blank">
                        <img src="//thumbnail9.coupangcdn.com/thumbnails/remote/492x492ex/image/retail/images/126526801505257-027701fa-b2f6-4323-997b-00dbe9c1b207.jpg" alt="í•˜ë¦¼ ë¸”ë™í˜í¼ ë‹­ê°€ìŠ´ì‚´" style="width: 120px; height: 120px; object-fit: cover; margin-right: 16px; border-radius: 4px;">
                    </a>
                    <div>
                        <h4 style="margin: 0; color: #1a73e8; font-size: 25px;">í•˜ë¦¼ ë¸”ë™í˜í¼ ë‹­ê°€ìŠ´ì‚´(ëƒ‰ì¥) 8ê°œì… </h4>
                        <p style="margin: 4px 0 0; font-size: 20px;">ë¬´ë£Œë°°ì†¡, ëª¨ë ˆ(ê¸ˆ) ë„ì°© ì˜ˆì •</p>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)

if __name__ == "__main__":
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "reanalyze" not in st.session_state:
        st.session_state.reanalyze = False
    if "search_results_available" not in st.session_state:
        st.session_state.search_results_available = False
    if "current_product" not in st.session_state:
        st.session_state.current_product = ""
    if "analyze_clicked" not in st.session_state:
        st.session_state.analyze_clicked = False
    if "show_ad" not in st.session_state:
        st.session_state.show_ad = True

    main()
